# ğŸ§ Audio Processing Workflow

## ğŸ§° Tools Used

<p align="center">
  <a href="https://www.python.org/downloads/release/python-3715/"><img src="https://www.python.org/static/community_logos/python-logo.png" height="50"></a>
  <a href="https://librosa.org/"><img src="https://librosa.org/images/librosa_logo_text.png" height="50"></a>
  <a href="https://pydub.com/"><img src="https://images.g2crowd.com/uploads/product/image/large_detail/large_detail_86c4f17e5b0c4fc3d86420b9c7c5894c/pydub.png" height="50"></a>
  <a href="https://numpy.org/"><img src="https://ebssistemas.com/file/2021/05/NumPy-200x80.png" height="50"></a>
  <a href="https://matplotlib.org/stable/index.html"><img src="https://matplotlib.org/2.0.2/plot_directive/mpl_examples/api/thumbnails/logo2.png" height="50"></a>
</p>

## 1. ğŸ“¥ Reading the Audio File

* We use `librosa` to load and process audio files.
* The sample is a **4-second** audio clip sampled at **22050 Hz**.
* Time-domain waveform plot:

![Original Signal](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/images/1.png)

ğŸ§ [Original Audio Sample](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/audios/mmmm.mov)

## 2. ğŸ” Voice Activity Detection (VAD) & Clipping

* VAD detects segments with human speech.
* Steps:

  * Normalize signal amplitude to \[-1, 1]
  * Apply a threshold to filter speech vs noise
  * Clip the audio to keep only speech segments

**VAD Output Plot:**

![VAD](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/images/2.png)

* **Red**: VAD mask
* **Blue**: Original signal
* **Selected range**: Retained for clipping

**Cropped Signal Plot:**

![Clipped Signal](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/images/3.png)

ğŸ§ [Original Audio Sample](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/audios/2.vad_croped.mov)

## 3. ğŸ“ˆ Pre-Emphasis

* Enhances high frequencies before analysis.
* Helps:

  1. Balance spectrum
  2. Avoid numerical issues in FFT
  3. Improve SNR

**Filter Equation:**

$$
y(t) = x(t) - \alpha x(t-1),\quad \alpha = 0.97
$$

**Plot after Pre-emphasis:**

![Pre-emphasis](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/images/4.png)

ğŸ§ [Pre-emphasized Audio](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/audios/3.preempha.mov)

## 4. ğŸ§© Splitting the Audio

* Audio is split into **10ms frames** using a sliding window.

**Frame Sequence Visualization:**

![Frames](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/images/frame.gif)

**Single Frame Example:**

![Single Frame](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/images/6.png)

## 5. ğŸªŸ Hann Window Function

* Reduces spectral leakage by smoothing frame edges.

**Window Function:**

$$
w(n) = 0.5 \left(1 - \cos\left({2\pi nN}\right)\right),\quad 0 \leq n \leq N
$$

**Windowed Frame Sequence:**

![Windowed Frames](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/images/windows.gif)

**Windowed Single Frame:**

![Windowed Frame](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/images/7.png)

<!-- ğŸ§ [Windowed Audio](https://user-images.githubusercontent.com/115212881/198013223-fdf9dc17-0994-4526-ba01-409dc48aa690.mov) -->

## 6. ğŸ”„ Time â†’ Frequency Domain (FFT)

* We apply **Fast Fourier Transform (FFT)** to convert from time to frequency domain.

**Time Domain:**

![Time](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/images/1.png)

**Frequency Domain:**

![Frequency](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/images/5.png)

## 7. ğŸŒˆ Spectrogram

* A **spectrogram** displays how frequency content changes over time.

**Axes:**

* X-axis: Time
* Y-axis: Frequency
* Color: Amplitude (Power in dB)

**Spectrogram:**

![Spectrogram](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/images/9.png)

## 8. ğŸ” MFCC Feature Extraction

* MFCCs capture **perceptual characteristics** of audio relevant to human hearing.
* Widely used in **speech recognition**.
* Frequency perception is:

  * Linear < 1kHz
  * Logarithmic > 1kHz

**Axes:**

* X-axis: Time
* Y-axis: MFCC coefficients (12 in our case)

**MFCC Plot:**

![MFCC](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/images/11.png)

## 9. ğŸ”„ Reconstructing Audio from MFCC

* Audio can be **partially reconstructed** from MFCCs with acceptable quality loss.

<!-- ğŸ§ [Reconstructed Audio](https://user-images.githubusercontent.com/115212881/198025434-f1d60eb5-5f70-449c-9f84-c630980dee05.mov) -->

ğŸ§ [Reconstructed Audio](https://raw.githubusercontent.com/WuChenDi/Audio-Processing/main/audios/4.reconstructed.mov)

## ğŸ“œ License

[MIT](./LICENSE) License Â© 2025-PRESENT [wudi](https://github.com/WuChenDi)
